{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data splitting for Tira parsing dataset\n",
    "Compare DataSAIL (Joeres et al 2025) w/ adversarial splitting (Søgaard et al 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Illegal instruction (core dumped)\n",
      "Illegal instruction (core dumped)\n",
      "Illegal instruction (core dumped)\n",
      "Illegal instruction (core dumped)\n"
     ]
    }
   ],
   "source": [
    "from datasail.sail import datasail\n",
    "from datasail.eval import eval_split\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import wasserstein_distance\n",
    "import numpy as np\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "Load sentences from text file and get TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7861,\n",
       " ['àprí jɜ̀dí ðáŋàlà',\n",
       "  'àprí jə̀və̀lɛ̀ðɔ́ ðáŋàlà',\n",
       "  'àprí jàvə́lɛ̀ðɛ́ ðàŋàlà',\n",
       "  'àprí jávə́lɛ̀ðà ðàŋàlà',\n",
       "  'ðə̀və̀lɛ́ðɔ́ áprì'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_file = '../data/sentences.txt'\n",
    "with open(sentences_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "sentences = [line.split(',')[0] for line in lines]\n",
    "len(sentences), sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7861, 26)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='char_wb', preprocessor=unidecode)\n",
    "vectors = vectorizer.fit_transform(sentences)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7861, 7861)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(vectors, vectors)\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_data = {i: sentence for i, sentence in enumerate(sentences)}\n",
    "e_sim = (list(range(len(sentences))), cosine_sim)\n",
    "run_count = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.5.3                                    \n",
      "===============================================================================\n",
      "(CVXPY) Dec 31 05:54:45 PM: Your problem has 150 variables, 53 constraints, and 0 parameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markjos/miniforge3/envs/parsing/lib/python3.12/site-packages/cvxpy/problems/problem.py:158: UserWarning: Objective contains too many subexpressions. Consider vectorizing your CVXPY code to speed up compilation.\n",
      "  warnings.warn(\"Objective contains too many subexpressions. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Dec 31 05:54:46 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Dec 31 05:54:46 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Dec 31 05:54:46 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Dec 31 05:54:46 PM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Dec 31 05:54:46 PM: Compiling problem (target solver=SCIP).\n",
      "(CVXPY) Dec 31 05:54:46 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCIP\n",
      "(CVXPY) Dec 31 05:54:46 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Dec 31 05:54:47 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Dec 31 05:54:47 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Dec 31 05:54:50 PM: Applying reduction SCIP\n",
      "(CVXPY) Dec 31 05:54:50 PM: Finished problem compilation (took 4.041e+00 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Dec 31 05:54:50 PM: Invoking solver SCIP  to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Dec 31 05:56:31 PM: Problem status: optimal_inaccurate\n",
      "(CVXPY) Dec 31 05:56:31 PM: Optimal value: 7.828e+06\n",
      "(CVXPY) Dec 31 05:56:31 PM: Compilation took 4.041e+00 seconds\n",
      "(CVXPY) Dec 31 05:56:31 PM: Solver (including time spent in interface) took 1.008e+02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markjos/miniforge3/envs/parsing/lib/python3.12/site-packages/cvxpy/problems/problem.py:1407: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.5.3                                    \n",
      "===============================================================================\n",
      "(CVXPY) Dec 31 05:56:35 PM: Your problem has 150 variables, 53 constraints, and 0 parameters.\n",
      "(CVXPY) Dec 31 05:56:35 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Dec 31 05:56:35 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Dec 31 05:56:35 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Dec 31 05:56:35 PM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Dec 31 05:56:36 PM: Compiling problem (target solver=SCIP).\n",
      "(CVXPY) Dec 31 05:56:36 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCIP\n",
      "(CVXPY) Dec 31 05:56:36 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Dec 31 05:56:37 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Dec 31 05:56:37 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Dec 31 05:56:40 PM: Applying reduction SCIP\n",
      "(CVXPY) Dec 31 05:56:40 PM: Finished problem compilation (took 4.482e+00 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Dec 31 05:56:40 PM: Invoking solver SCIP  to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Dec 31 05:58:21 PM: Problem status: optimal_inaccurate\n",
      "(CVXPY) Dec 31 05:58:21 PM: Optimal value: 8.127e+06\n",
      "(CVXPY) Dec 31 05:58:21 PM: Compilation took 4.482e+00 seconds\n",
      "(CVXPY) Dec 31 05:58:21 PM: Solver (including time spent in interface) took 1.008e+02 seconds\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.5.3                                    \n",
      "===============================================================================\n",
      "(CVXPY) Dec 31 05:58:28 PM: Your problem has 150 variables, 53 constraints, and 0 parameters.\n",
      "(CVXPY) Dec 31 05:58:28 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Dec 31 05:58:28 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Dec 31 05:58:28 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Dec 31 05:58:28 PM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Dec 31 05:58:29 PM: Compiling problem (target solver=SCIP).\n",
      "(CVXPY) Dec 31 05:58:29 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCIP\n",
      "(CVXPY) Dec 31 05:58:29 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Dec 31 05:58:30 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Dec 31 05:58:30 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Dec 31 05:58:35 PM: Applying reduction SCIP\n",
      "(CVXPY) Dec 31 05:58:35 PM: Finished problem compilation (took 6.517e+00 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Dec 31 05:58:35 PM: Invoking solver SCIP  to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Dec 31 06:00:16 PM: Problem status: optimal_inaccurate\n",
      "(CVXPY) Dec 31 06:00:16 PM: Optimal value: 8.040e+06\n",
      "(CVXPY) Dec 31 06:00:16 PM: Compilation took 6.517e+00 seconds\n",
      "(CVXPY) Dec 31 06:00:16 PM: Solver (including time spent in interface) took 1.010e+02 seconds\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.5.3                                    \n",
      "===============================================================================\n",
      "(CVXPY) Dec 31 06:00:23 PM: Your problem has 150 variables, 53 constraints, and 0 parameters.\n",
      "(CVXPY) Dec 31 06:00:23 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Dec 31 06:00:23 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Dec 31 06:00:23 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Dec 31 06:00:23 PM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Dec 31 06:00:24 PM: Compiling problem (target solver=SCIP).\n",
      "(CVXPY) Dec 31 06:00:24 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCIP\n",
      "(CVXPY) Dec 31 06:00:24 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Dec 31 06:00:25 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Dec 31 06:00:25 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Dec 31 06:00:28 PM: Applying reduction SCIP\n",
      "(CVXPY) Dec 31 06:00:28 PM: Finished problem compilation (took 4.683e+00 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Dec 31 06:00:28 PM: Invoking solver SCIP  to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Dec 31 06:02:09 PM: Problem status: optimal_inaccurate\n",
      "(CVXPY) Dec 31 06:02:09 PM: Optimal value: 7.907e+06\n",
      "(CVXPY) Dec 31 06:02:09 PM: Compilation took 4.683e+00 seconds\n",
      "(CVXPY) Dec 31 06:02:09 PM: Solver (including time spent in interface) took 1.009e+02 seconds\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.5.3                                    \n",
      "===============================================================================\n",
      "(CVXPY) Dec 31 06:02:15 PM: Your problem has 150 variables, 53 constraints, and 0 parameters.\n",
      "(CVXPY) Dec 31 06:02:16 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Dec 31 06:02:16 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Dec 31 06:02:16 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Dec 31 06:02:16 PM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Dec 31 06:02:17 PM: Compiling problem (target solver=SCIP).\n",
      "(CVXPY) Dec 31 06:02:17 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCIP\n",
      "(CVXPY) Dec 31 06:02:17 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Dec 31 06:02:17 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Dec 31 06:02:17 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Dec 31 06:02:20 PM: Applying reduction SCIP\n",
      "(CVXPY) Dec 31 06:02:20 PM: Finished problem compilation (took 4.429e+00 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Dec 31 06:02:20 PM: Invoking solver SCIP  to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Dec 31 06:04:01 PM: Problem status: optimal_inaccurate\n",
      "(CVXPY) Dec 31 06:04:01 PM: Optimal value: 8.201e+06\n",
      "(CVXPY) Dec 31 06:04:01 PM: Compilation took 4.429e+00 seconds\n",
      "(CVXPY) Dec 31 06:04:01 PM: Solver (including time spent in interface) took 1.007e+02 seconds\n"
     ]
    }
   ],
   "source": [
    "techniques, inters, groups = datasail(\n",
    "    techniques=[\"C1e\"],\n",
    "    splits=[7,2,1],\n",
    "    names=[\"train\",\"validation\",\"test\"],\n",
    "    runs=run_count,\n",
    "    epsilon=0.1,\n",
    "    solver=\"SCIP\",\n",
    "    e_type=\"O\",\n",
    "    e_data=e_data,\n",
    "    e_sim=e_sim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasail_assignments = techniques['C1e']\n",
    "len(datasail_assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial splitting\n",
    "Based on Wasserstein distance. Code adapted from [probing_utils.py](https://github.com/google-research/google-research/blob/master/talk_about_random_splits/probing/probing_utils.py) on Github on 31 Dec 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_with_wasserstein(vectors,\n",
    "                           test_set_size=0.1,\n",
    "                           no_of_trials=1,\n",
    "                           leaf_size=5,\n",
    "):\n",
    "    \"\"\"Finds test sets by maximizing Wasserstein distances among the given texts.\n",
    "  \n",
    "    This is separating the given texts into training/dev and test sets based on an\n",
    "    approximate Wasserstein method. First all texts are indexed in a nearest\n",
    "    neighbors structure. Then a new test centroid is sampled randomly, from which\n",
    "    the nearest neighbors in Wasserstein space are extracted. Those constitute\n",
    "    the new test set.\n",
    "    Similarity is computed based on document-term counts.\n",
    "  \n",
    "    Args:\n",
    "      texts: Texts to split into training/dev and test sets.\n",
    "      test_set_size: Number of elements the new test set should contain.\n",
    "      no_of_trials: Number of test sets requested.\n",
    "      min_df: Mainly for speed-up and memory efficiency. All tokens must occur at\n",
    "        least this many times to be considered in the Wasserstein computation.\n",
    "      leaf_size: Leaf size parameter of the nearest neighbor search. Set high\n",
    "        values for slower, but less memory-heavy computation.\n",
    "  \n",
    "    Returns:\n",
    "      Returns a List of test set indices, one for each trial. The indices\n",
    "      correspond to the items in `texts` that should be part of the test set.\n",
    "    \"\"\"\n",
    "    print('Creating tree structure.')\n",
    "    nn_tree = neighbors.NearestNeighbors(\n",
    "        n_neighbors=int(test_set_size*vectors.shape[0]),\n",
    "        algorithm='ball_tree',\n",
    "        leaf_size=leaf_size,\n",
    "        metric=wasserstein_distance)\n",
    "    nn_tree.fit(vectors)\n",
    "    print('Sampling test sets.')\n",
    "    test_set_indices = []\n",
    "\n",
    "    for trial in range(no_of_trials):\n",
    "        print('Trial set: %d.', trial)\n",
    "        # Sample random test centroid.\n",
    "        sampled_point = np.random.randint(\n",
    "            vectors.max().max() + 1, size=(1, vectors.shape[1]))\n",
    "        nearest_neighbors = nn_tree.kneighbors(sampled_point, return_distance=False)\n",
    "        # We queried for only one datapoint.\n",
    "        nearest_neighbors = nearest_neighbors[0]\n",
    "        print(nearest_neighbors[:10])\n",
    "        test_set_indices.append(nearest_neighbors)\n",
    "\n",
    "    return test_set_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tree structure.\n",
      "Sampling test sets.\n",
      "Trial set: %d. 0\n",
      "[7083 7084 7170 7618 7251 7217 7216 6999 7005 7004]\n",
      "Trial set: %d. 1\n",
      "[7083 7084 7170 7618 7251 7217 7216 6999 7005 7004]\n",
      "Trial set: %d. 2\n",
      "[7083 7084 7170 7618 7251 7217 7216 6999 7005 7004]\n",
      "Trial set: %d. 3\n",
      "[7083 7084 7170 7618 7251 7217 7216 6999 7005 7004]\n",
      "Trial set: %d. 4\n",
      "[7083 7084 7170 7618 7251 7217 7216 6999 7005 7004]\n",
      "Creating tree structure.\n",
      "Sampling test sets.\n",
      "Trial set: %d. 0\n",
      "[6109 1019 3483 6197 1369 6150 4623 3484 2214 2213]\n",
      "Creating tree structure.\n",
      "Sampling test sets.\n",
      "Trial set: %d. 0\n",
      "[6109 1019 3483 6197 1369 6150 4623 3484 2214 2213]\n",
      "Creating tree structure.\n",
      "Sampling test sets.\n",
      "Trial set: %d. 0\n",
      "[6109 1019 3483 6197 1369 6150 4623 3484 2214 2213]\n",
      "Creating tree structure.\n",
      "Sampling test sets.\n",
      "Trial set: %d. 0\n",
      "[6109 1019 3483 6197 1369 6150 4623 3484 2214 2213]\n",
      "Creating tree structure.\n",
      "Sampling test sets.\n",
      "Trial set: %d. 0\n",
      "[6109 1019 3483 6197 1369 6150 4623 3484 2214 2213]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_splits_w_wasserstein(vectors, sizes=[0.7, 0.2, 0.1], run_count=run_count):\n",
    "    train_size, val_size, test_size = sizes\n",
    "\n",
    "    assignment_list = []\n",
    "    val_indices = split_with_wasserstein(vectors, val_size, no_of_trials=run_count)\n",
    "    for val_set in val_indices:\n",
    "        remaining_idcs = [i for i in range(vectors.shape[0]) if i not in val_set]\n",
    "        remaining_vectors = vectors[remaining_idcs]\n",
    "        test_set = split_with_wasserstein(remaining_vectors, test_size)[0]\n",
    "\n",
    "        train_set = [i for i in remaining_idcs if i not in test_set]\n",
    "\n",
    "        assignments = {}\n",
    "        assignments.update({i: 'train' for i in train_set})\n",
    "        assignments.update({i: 'validation' for i in val_set})\n",
    "        assignments.update({i: 'test' for i in test_set})\n",
    "        assignment_list.append(assignments)\n",
    "\n",
    "    return assignment_list\n",
    "\n",
    "sogaard_assignments = get_splits_w_wasserstein(vectors.toarray())\n",
    "len(sogaard_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for i, assignment in enumerate(datasail_assignments):\n",
    "    scaled_leakage, total_leakage, max_leakage = eval_split(\n",
    "        datatype=\"O\",\n",
    "        weights=None,\n",
    "        distance=None,\n",
    "        dist_conv=None,\n",
    "        data=e_data,\n",
    "        similarity=e_sim,\n",
    "        split_assignment=assignment,\n",
    "    )\n",
    "    rows.append({\n",
    "        'scaled_leakage': scaled_leakage,\n",
    "        'total_leakage': total_leakage,\n",
    "        'max_leakage': max_leakage,\n",
    "        'run': i,\n",
    "        'method': 'datasail',\n",
    "    })\n",
    "\n",
    "for i, assignment in enumerate(sogaard_assignments):\n",
    "    scaled_leakage, total_leakage, max_leakage = eval_split(\n",
    "        datatype=\"O\",\n",
    "        weights=None,\n",
    "        distance=None,\n",
    "        dist_conv=None,\n",
    "        data=e_data,\n",
    "        similarity=e_sim,\n",
    "        split_assignment=assignment,\n",
    "    )\n",
    "    rows.append({\n",
    "        'scaled_leakage': scaled_leakage,\n",
    "        'total_leakage': total_leakage,\n",
    "        'max_leakage': max_leakage,\n",
    "        'run': i,\n",
    "        'method': 'sogaard',\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_leakage</th>\n",
       "      <th>total_leakage</th>\n",
       "      <th>max_leakage</th>\n",
       "      <th>run</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.408876</td>\n",
       "      <td>1.565622e+07</td>\n",
       "      <td>3.829083e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>datasail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.424479</td>\n",
       "      <td>1.625365e+07</td>\n",
       "      <td>3.829083e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>datasail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.419963</td>\n",
       "      <td>1.608074e+07</td>\n",
       "      <td>3.829083e+07</td>\n",
       "      <td>2</td>\n",
       "      <td>datasail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.412973</td>\n",
       "      <td>1.581309e+07</td>\n",
       "      <td>3.829083e+07</td>\n",
       "      <td>3</td>\n",
       "      <td>datasail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.428336</td>\n",
       "      <td>1.640136e+07</td>\n",
       "      <td>3.829083e+07</td>\n",
       "      <td>4</td>\n",
       "      <td>datasail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.399829</td>\n",
       "      <td>1.530979e+07</td>\n",
       "      <td>3.829083e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>sogaard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.399829</td>\n",
       "      <td>1.530979e+07</td>\n",
       "      <td>3.829083e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>sogaard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.399829</td>\n",
       "      <td>1.530979e+07</td>\n",
       "      <td>3.829083e+07</td>\n",
       "      <td>2</td>\n",
       "      <td>sogaard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.399829</td>\n",
       "      <td>1.530979e+07</td>\n",
       "      <td>3.829083e+07</td>\n",
       "      <td>3</td>\n",
       "      <td>sogaard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.399829</td>\n",
       "      <td>1.530979e+07</td>\n",
       "      <td>3.829083e+07</td>\n",
       "      <td>4</td>\n",
       "      <td>sogaard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_leakage  total_leakage   max_leakage  run    method\n",
       "0        0.408876   1.565622e+07  3.829083e+07    0  datasail\n",
       "1        0.424479   1.625365e+07  3.829083e+07    1  datasail\n",
       "2        0.419963   1.608074e+07  3.829083e+07    2  datasail\n",
       "3        0.412973   1.581309e+07  3.829083e+07    3  datasail\n",
       "4        0.428336   1.640136e+07  3.829083e+07    4  datasail\n",
       "5        0.399829   1.530979e+07  3.829083e+07    0   sogaard\n",
       "6        0.399829   1.530979e+07  3.829083e+07    1   sogaard\n",
       "7        0.399829   1.530979e+07  3.829083e+07    2   sogaard\n",
       "8        0.399829   1.530979e+07  3.829083e+07    3   sogaard\n",
       "9        0.399829   1.530979e+07  3.829083e+07    4   sogaard"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leakage_df = pd.DataFrame(rows)\n",
    "leakage_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Sogaard's method is actually doing a tiny bit better, so we'll stick with it. Let's save the split to HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_split = sogaard_assignments[0]\n",
    "train_idcs = [k for k, v in final_split.items() if v == 'train']\n",
    "val_idcs = [k for k, v in final_split.items() if v == 'validation']\n",
    "test_idcs = [k for k, v in final_split.items() if v == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markjos/miniforge3/envs/parsing/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['orig_text', 'translation', 'checked_by_pi', 'checked_by_ra', 'reviewer', 'updated_txt', 'updated_gloss'],\n",
       "        num_rows: 7861\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "ds = load_dataset('tira-parsing/tira-parsing')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['orig_text', 'translation', 'checked_by_pi', 'checked_by_ra', 'reviewer', 'updated_txt', 'updated_gloss'],\n",
       "        num_rows: 5747\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['orig_text', 'translation', 'checked_by_pi', 'checked_by_ra', 'reviewer', 'updated_txt', 'updated_gloss'],\n",
       "        num_rows: 1486\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['orig_text', 'translation', 'checked_by_pi', 'checked_by_ra', 'reviewer', 'updated_txt', 'updated_gloss'],\n",
       "        num_rows: 628\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_dict = {}\n",
    "\n",
    "for split, indices in [\n",
    "    ('train', train_idcs),\n",
    "    ('validation', val_idcs),\n",
    "    ('test', test_idcs),\n",
    "]:\n",
    "    ds_dict[split] = ds['train'].select(indices)\n",
    "\n",
    "ds_dict = DatasetDict(ds_dict)\n",
    "ds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  1.78ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  171kB /  171kB,  427kB/s  \n",
      "New Data Upload: 100%|██████████|  171kB /  171kB,  427kB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.97s/ shards]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.83ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 40.7kB / 40.7kB,  0.00B/s  \n",
      "New Data Upload: 100%|██████████| 40.7kB / 40.7kB,  0.00B/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.46 shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 17.88ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 28.7kB / 28.7kB,  0.00B/s  \n",
      "New Data Upload: 100%|██████████| 28.7kB / 28.7kB,  0.00B/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.65 shards/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/tira-parsing/tira-parsing/commit/8402f9250977cea1deb0dc199c87ad8138a1bf17', commit_message='Generate splits based on Wasserstein distance to minimize overlap', commit_description='', oid='8402f9250977cea1deb0dc199c87ad8138a1bf17', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/tira-parsing/tira-parsing', endpoint='https://huggingface.co', repo_type='dataset', repo_id='tira-parsing/tira-parsing'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_dict.push_to_hub(\n",
    "    repo_id = 'tira-parsing/tira-parsing',\n",
    "    commit_message=\"Generate splits based on Wasserstein distance to minimize overlap\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parsing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
